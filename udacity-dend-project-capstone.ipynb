{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US I94 Immigration Insights \n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This Project creates a Data Lake type of ETL pipeline to process, clean and store data related to US I94 Immigration data. Data can be used to analyse immigration flow to and from US through different airports.  \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import glob\n",
    "import configparser\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat\n",
      "data/airport_codes.csv\n",
      "data/iso-3166-country-codes.csv\n",
      "data/i94_airport_codes.xlsx\n",
      "data/i94_country_codes.xlsx\n",
      "data/output_data/\n",
      "local\n",
      "parquet\n"
     ]
    }
   ],
   "source": [
    "# Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "# NOTE: Use these if using AWS S3 as a storage\n",
    "INPUT_DATA = config['AWS']['INPUT_DATA']\n",
    "OUTPUT_DATA = config['AWS']['OUTPUT_DATA']\n",
    "\n",
    "# NOTE: Use these if using local storage\n",
    "INPUT_DATA_LOCAL          = config['LOCAL']['INPUT_DATA_LOCAL']\n",
    "INPUT_DATA_I94_LOCAL      = config['LOCAL']['INPUT_DATA_I94_LOCAL']\n",
    "INPUT_DATA_AIRPORT_LOCAL  = config['LOCAL']['INPUT_DATA_AIRPORT_LOCAL']\n",
    "INPUT_DATA_COUNTRY_LOCAL  = config['LOCAL']['INPUT_DATA_COUNTRY_LOCAL']\n",
    "INPUT_DATA_AIRPORT_I94_LOCAL  = config['LOCAL']['INPUT_DATA_AIRPORT_I94_LOCAL']\n",
    "INPUT_DATA_COUNTRY_I94_LOCAL  = config['LOCAL']['INPUT_DATA_COUNTRY_I94_LOCAL']\n",
    "OUTPUT_DATA_LOCAL         = config['LOCAL']['OUTPUT_DATA_LOCAL']\n",
    "\n",
    "# NOTE: Use these when storing data on server.\n",
    "INPUT_DATA_I94_SERVER     = config['SERVER']['INPUT_DATA_I94_SERVER']\n",
    "INPUT_DATA_AIRPORT_SERVER = config['SERVER']['INPUT_DATA_AIRPORT_SERVER']\n",
    "INPUT_DATA_COUNTRY_SERVER = config['SERVER']['INPUT_DATA_COUNTRY_SERVER']\n",
    "OUTPUT_DATA_SERVER        = config['SERVER']['OUTPUT_DATA_SERVER']\n",
    "\n",
    "# NOTE: Use these when storing data on AWS.\n",
    "INPUT_DATA_I94            = config['AWS']['INPUT_DATA_I94']\n",
    "INPUT_DATA_AIRPORT        = config['AWS']['INPUT_DATA_AIRPORT']\n",
    "INPUT_DATA_COUNTRY        = config['AWS']['INPUT_DATA_COUNTRY']\n",
    "OUTPUT_DATA               = config['AWS']['OUTPUT_DATA']\n",
    "\n",
    "DATA_LOCATION             = config['COMMON']['DATA_LOCATION']\n",
    "DATA_STORAGE              = config['COMMON']['DATA_STORAGE']\n",
    "\n",
    "#print(AWS_ACCESS_KEY_ID)\n",
    "#print(AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "print(INPUT_DATA_LOCAL)\n",
    "print(INPUT_DATA_I94_LOCAL)\n",
    "print(INPUT_DATA_AIRPORT_LOCAL)\n",
    "print(INPUT_DATA_COUNTRY_LOCAL)\n",
    "print(INPUT_DATA_AIRPORT_I94_LOCAL)\n",
    "print(INPUT_DATA_COUNTRY_I94_LOCAL)\n",
    "print(OUTPUT_DATA_LOCAL)\n",
    "print(DATA_LOCATION)\n",
    "print(DATA_STORAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "_Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc_\n",
    "\n",
    "Scope of the project is to create an ETL pipeline for processing, cleaning and storing data related to US I94 immigration data, and country codes.  \n",
    "\n",
    "Output of the ETL pipeline: processed data stored in Star schema model to parquet files. \n",
    "Tools: python, pandas, pyspark, (Amazon AWS S3)\n",
    "\n",
    "#### Describe and Gather Data \n",
    "_Describe the data sets you're using. Where did it come from? What type of information is included?_\n",
    "\n",
    "Project's data contains the following pieces:\n",
    "* **data/18-83510-I94-Data-2016/**: US I94 immigration data from 2016 (Jan-Dec).\n",
    "    * Source: https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "    * Description: I94_SAS_Labels_Descriptions.txt file contains descriptions for the I94 data.\n",
    "        * I94 dataset has SAS7BDAT file per each month of the year (e.g. i94_jan16_sub.sas7bdat).\n",
    "        * Each file contains about 3M rows\n",
    "        * Data has 28 columns containing information about event date, arriving person, airport, airline, etc.\n",
    "    * I94 immigration data example:\n",
    "    * ![I94-immigration-data example](./Udacity-DEND-Project-Capstone-I94ImmigrationData-20190812-2.png)\n",
    "    * NOTE: This data is behind a pay wall and need to be purchased to get access. Data is available for Udacity DEND course.\n",
    "    \n",
    "* **data/i94_airport_codes.xlsx**: Airport codes and related cities defined in I94 data description file.\n",
    "    * Source: https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "    * Description: I94 Airport codes data contains information about different airports around the world.\n",
    "        * Columns: i94port, i94_airport_name\n",
    "        * Data has 660 rows and 2 columns.\n",
    "    * NOTE: I94 data uses its own codes for airports instead of using standard codes (like IATA). Therefore, I94 airport codes have been taken from I94 data description file and processed for ETL use.  \n",
    "    * Airport Code example:\n",
    "    * ![I94-AirportCode-data example](./Udacity-DEND-Project-Capstone-I94AirportCodeData-20190813-4.png)\n",
    "\n",
    "* **data/i94_country_codes.xlsx**: Country codes defined in US I94 Immigration data description file. \n",
    "    * Source: https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "    * Description: I94 Country codes data contains information about countries people come to US from.\n",
    "        * Columns: i94cit, i94_country_code\n",
    "        * Data has 289 rows and 2 columns.\n",
    "    * NOTE: I94 data uses its own codes for countries instead of using ISO-3166 standard codes. Therefore, I94 country codes have been taken from I94 data description file and processed for ETL use.\n",
    "    * Country Code example:\n",
    "    * ![CountryCode-data example](./Udacity-DEND-Project-Capstone-I94CountryCodeData-20190813-5.png)    \n",
    "  \n",
    "* **data/airport-codes.csv**: Airport codes and related cities.\n",
    "    * Source: https://datahub.io/core/airport-codes#data\n",
    "    * Description: Airpot codes data contains information about different airports around the world.\n",
    "        * Columns: Airport code, name, type, location, etc.\n",
    "        * Data has 48304 rows and 12 columns.\n",
    "    * Airport Code example:\n",
    "    * ![AirportCode-data example](./Udacity-DEND-Project-Capstone-AirportCodeData-20190812-3.png)\n",
    "\n",
    "* **data/iso-3166-country-codes.json**: World country codes (ISO-3166)\n",
    "    * Source: https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes\n",
    "    ISO-3166-1 and ISO-3166-2 Country and Dependent Territories Lists with UN Regional Codes\n",
    "    * ISO-3166: https://www.iso.org/iso-3166-country-codes.html\n",
    "    * Country Code example:\n",
    "    * ![CountryCode-data example](./Udacity-DEND-Project-Capstone-CountryCodesData-20190804-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define config and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config\n",
    "if DATA_LOCATION == \"local\":\n",
    "    input_data        = INPUT_DATA_LOCAL\n",
    "    i94_data          = INPUT_DATA_I94_LOCAL\n",
    "    airport_codes     = INPUT_DATA_AIRPORT_LOCAL\n",
    "    country_codes     = INPUT_DATA_COUNTRY_LOCAL\n",
    "    airport_codes_i94 = INPUT_DATA_AIRPORT_I94_LOCAL\n",
    "    country_codes_i94 = INPUT_DATA_COUNTRY_I94_LOCAL\n",
    "    output_data       = OUTPUT_DATA_LOCAL\n",
    "elif DATA_LOCATION == \"server\":\n",
    "    input_data_bucket = INPUT_DATA_SERVER\n",
    "    i94_data          = INPUT_DATA_I94_SERVER\n",
    "    airport_codes     = INPUT_DATA_AIRPORT_SERVER\n",
    "    country_codes     = INPUT_COUNTRY_SERVER\n",
    "    airport_codes_i94 = INPUT_DATA_AIRPORT_I94_SERVER\n",
    "    country_codes_i94 = INPUT_DATA_COUNTRY_I94_SERVER\n",
    "    output_data       = OUTPUT_DATA_SERVER\n",
    "elif DATA_LOCATION == \"aws\":\n",
    "    input_data_bucket = INPUT_DATA\n",
    "    i94_data          = INPUT_DATA_I94\n",
    "    airport_codes     = INPUT_DATA_AIRPORT\n",
    "    country_codes     = INPUT_COUNTRY\n",
    "    airport_codes_i94 = INPUT_DATA_AIRPORT_I94\n",
    "    country_codes_i94 = INPUT_DATA_COUNTRY_I94\n",
    "    output_data       = OUTPUT_DATA\n",
    "    \n",
    "if DATA_STORAGE == \"postgresql\":\n",
    "    pass\n",
    "elif DATA_STORAGE == \"parquet\":\n",
    "    data_storage      = DATA_STORAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read I94 immigration data:\n",
    "#i94_df = pd.read_sas(i94_data, 'sas7bdat', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read airport code data:\n",
    "airport_codes_df = pd.read_csv(airport_codes, header=0, sep=',')\n",
    "\n",
    "# Read Global country codes data:\n",
    "#country_codes_df = pd.read_json(country_codes, orient=\"records\")\n",
    "country_codes_df = pd.read_csv(country_codes, header=0)\n",
    "\n",
    "# Read I94 Airport codes data:\n",
    "airport_codes_i94_df = pd.read_excel(airport_codes_i94, header=0, index_col=0)\n",
    "\n",
    "# Read I94 Country codes data:\n",
    "country_codes_i94_df = pd.read_excel(country_codes_i94, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Show data snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I94 immigration data\n",
    "i94_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>alpha-2</th>\n",
       "      <th>alpha-3</th>\n",
       "      <th>country-code</th>\n",
       "      <th>iso_3166-2</th>\n",
       "      <th>region</th>\n",
       "      <th>sub-region</th>\n",
       "      <th>intermediate-region</th>\n",
       "      <th>region-code</th>\n",
       "      <th>sub-region-code</th>\n",
       "      <th>intermediate-region-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>ISO 3166-2:AF</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "      <td>ALA</td>\n",
       "      <td>248</td>\n",
       "      <td>ISO 3166-2:AX</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "      <td>ISO 3166-2:AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12</td>\n",
       "      <td>ISO 3166-2:DZ</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>ISO 3166-2:AS</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name alpha-2 alpha-3  country-code     iso_3166-2   region  \\\n",
       "0     Afghanistan      AF     AFG             4  ISO 3166-2:AF     Asia   \n",
       "1   Åland Islands      AX     ALA           248  ISO 3166-2:AX   Europe   \n",
       "2         Albania      AL     ALB             8  ISO 3166-2:AL   Europe   \n",
       "3         Algeria      DZ     DZA            12  ISO 3166-2:DZ   Africa   \n",
       "4  American Samoa      AS     ASM            16  ISO 3166-2:AS  Oceania   \n",
       "\n",
       "        sub-region intermediate-region  region-code  sub-region-code  \\\n",
       "0    Southern Asia                 NaN        142.0             34.0   \n",
       "1  Northern Europe                 NaN        150.0            154.0   \n",
       "2  Southern Europe                 NaN        150.0             39.0   \n",
       "3  Northern Africa                 NaN          2.0             15.0   \n",
       "4        Polynesia                 NaN          9.0             61.0   \n",
       "\n",
       "   intermediate-region-code  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_airport_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94port</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'ALC'</th>\n",
       "      <td>'ALCAN, AK             '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'ANC'</th>\n",
       "      <td>'ANCHORAGE, AK         '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'BAR'</th>\n",
       "      <td>'BAKER AAF - BAKER ISLAND, AK'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'DAC'</th>\n",
       "      <td>'DALTONS CACHE, AK     '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'PIZ'</th>\n",
       "      <td>'DEW STATION PT LAY DEW, AK'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        i94_airport_name\n",
       "i94port                                 \n",
       "   'ALC'        'ALCAN, AK             '\n",
       "   'ANC'        'ANCHORAGE, AK         '\n",
       "   'BAR'  'BAKER AAF - BAKER ISLAND, AK'\n",
       "   'DAC'        'DALTONS CACHE, AK     '\n",
       "   'PIZ'    'DEW STATION PT LAY DEW, AK'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes_i94_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_country_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94cit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>MEXICO'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>'AFGHANISTAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>'ALBANIA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>'ALGERIA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>'ANDORRA'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i94_country_name\n",
       "i94cit                 \n",
       "582             MEXICO'\n",
       "236       'AFGHANISTAN'\n",
       "101           'ALBANIA'\n",
       "316           'ALGERIA'\n",
       "102           'ANDORRA'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_i94_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder\\\n",
    "#                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "#                     .getOrCreate()\n",
    "#from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "                    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Read I94 immigration data to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_schema = t.StructType([\n",
    "                            t.StructField(\"alpha-2\", t.StringType(), False),\n",
    "                            t.StructField(\"alpha-3\", t.StringType(), False),\n",
    "                            t.StructField(\"country-code\", t.IntegerType(), False),\n",
    "                            t.StructField(\"intermediate-region\", t.StringType(), False),\n",
    "                            t.StructField(\"intermediate-region-code\", t.StringType(), False),\n",
    "                            t.StructField(\"iso-3166-2\", t.StringType(), False),\n",
    "                            t.StructField(\"name\", t.StringType(), False),\n",
    "                            t.StructField(\"region\", t.StringType(), True),\n",
    "                            t.StructField(\"region-code\", t.StringType(), True),\n",
    "                            t.StructField(\"sub-region\", t.StringType(), True),\n",
    "                            t.StructField(\"sub-region-code\", t.StringType(), True),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_df_spark =spark.read.format('com.github.saurfang.sas.spark').load(i94_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+\n",
      "|cicid|i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum      |fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+\n",
      "|7.0  |2016.0|1.0   |101.0 |101.0 |BOS    |20465.0|1.0    |MA     |null   |20.0  |3.0    |1.0  |null    |null    |null |T      |null   |null   |null   |1996.0 |D/S     |M     |null  |LH     |3.46608285E8|424  |F1      |\n",
      "|8.0  |2016.0|1.0   |101.0 |101.0 |BOS    |20465.0|1.0    |MA     |null   |20.0  |3.0    |1.0  |null    |null    |null |T      |null   |null   |null   |1996.0 |D/S     |M     |null  |LH     |3.46627585E8|424  |F1      |\n",
      "|9.0  |2016.0|1.0   |101.0 |101.0 |BOS    |20469.0|1.0    |CT     |20480.0|17.0  |2.0    |1.0  |null    |null    |null |T      |N      |null   |M      |1999.0 |07152016|F     |null  |AF     |3.81092385E8|338  |B2      |\n",
      "|10.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20469.0|1.0    |CT     |20499.0|45.0  |2.0    |1.0  |null    |null    |null |T      |N      |null   |M      |1971.0 |07152016|F     |null  |AF     |3.81087885E8|338  |B2      |\n",
      "|11.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20469.0|1.0    |CT     |20499.0|12.0  |2.0    |1.0  |null    |null    |null |T      |N      |null   |M      |2004.0 |07152016|M     |null  |AF     |3.81078685E8|338  |B2      |\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_spark.printSchema()\n",
    "i94_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Read Airport code data to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airport_schema = t.StructType([\n",
    "#                            t.StructField(\"dt\", t.StringType(), False),\n",
    "#                            t.StructField(\"AverageTemperature\", t.FloatType(), True),\n",
    "#                            t.StructField(\"AverageTemperatureUncertainty\", t.FloatType(), True),\n",
    "#                            t.StructField(\"City\", t.StringType(), False),\n",
    "#                            t.StructField(\"Country\", t.StringType(), False),\n",
    "#                            t.StructField(\"Latitude\", t.StringType(), False),\n",
    "#                            t.StructField(\"Longitude\", t.StringType(), False),\n",
    "#                        ])\n",
    "airport_codes_iata_df_spark = spark.read.csv(airport_codes, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "|ident|type         |name                              |elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|coordinates                          |\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "|00A  |heliport     |Total Rf Heliport                 |11          |NA       |US         |US-PA     |Bensalem    |00A     |null     |00A       |-74.93360137939453, 40.07080078125   |\n",
      "|00AA |small_airport|Aero B Ranch Airport              |3435        |NA       |US         |US-KS     |Leoti       |00AA    |null     |00AA      |-101.473911, 38.704022               |\n",
      "|00AK |small_airport|Lowell Field                      |450         |NA       |US         |US-AK     |Anchor Point|00AK    |null     |00AK      |-151.695999146, 59.94919968          |\n",
      "|00AL |small_airport|Epps Airpark                      |820         |NA       |US         |US-AL     |Harvest     |00AL    |null     |00AL      |-86.77030181884766, 34.86479949951172|\n",
      "|00AR |closed       |Newport Hospital & Clinic Heliport|237         |NA       |US         |US-AR     |Newport     |null    |null     |null      |-91.254898, 35.6087                  |\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_iata_df_spark.printSchema()\n",
    "airport_codes_iata_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Read ISO Country Code data to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_schema = t.StructType([\n",
    "                            t.StructField(\"alpha_2\", t.StringType(), False),\n",
    "                            t.StructField(\"alpha_3\", t.StringType(), False),\n",
    "                            t.StructField(\"country_code\", t.StringType(), False),\n",
    "                            t.StructField(\"intermediate_region\", t.StringType(), False),\n",
    "                            t.StructField(\"intermediate_region_code\", t.StringType(), False),\n",
    "                            t.StructField(\"iso_3166_2\", t.StringType(), False),\n",
    "                            t.StructField(\"name\", t.StringType(), False),\n",
    "                            t.StructField(\"region\", t.StringType(), True),\n",
    "                            t.StructField(\"region_code\", t.StringType(), True),\n",
    "                            t.StructField(\"sub_region\", t.StringType(), True),\n",
    "                            t.StructField(\"sub_region_code\", t.StringType(), True),\n",
    "                        ])\n",
    "country_codes_iso_df_spark = spark.createDataFrame(country_codes_df, schema=country_code_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alpha_2: string (nullable = false)\n",
      " |-- alpha_3: string (nullable = false)\n",
      " |-- country_code: string (nullable = false)\n",
      " |-- intermediate_region: string (nullable = false)\n",
      " |-- intermediate_region_code: string (nullable = false)\n",
      " |-- iso_3166_2: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- region: string (nullable = true)\n",
      " |-- region_code: string (nullable = true)\n",
      " |-- sub_region: string (nullable = true)\n",
      " |-- sub_region_code: string (nullable = true)\n",
      "\n",
      "+--------------+-------+------------+-------------------+------------------------+----------+---------------+------+-----------+----------+---------------+\n",
      "|alpha_2       |alpha_3|country_code|intermediate_region|intermediate_region_code|iso_3166_2|name           |region|region_code|sub_region|sub_region_code|\n",
      "+--------------+-------+------------+-------------------+------------------------+----------+---------------+------+-----------+----------+---------------+\n",
      "|Afghanistan   |AF     |AFG         |4                  |ISO 3166-2:AF           |Asia      |Southern Asia  |NaN   |142.0      |34.0      |NaN            |\n",
      "|Åland Islands |AX     |ALA         |248                |ISO 3166-2:AX           |Europe    |Northern Europe|NaN   |150.0      |154.0     |NaN            |\n",
      "|Albania       |AL     |ALB         |8                  |ISO 3166-2:AL           |Europe    |Southern Europe|NaN   |150.0      |39.0      |NaN            |\n",
      "|Algeria       |DZ     |DZA         |12                 |ISO 3166-2:DZ           |Africa    |Northern Africa|NaN   |2.0        |15.0      |NaN            |\n",
      "|American Samoa|AS     |ASM         |16                 |ISO 3166-2:AS           |Oceania   |Polynesia      |NaN   |9.0        |61.0      |NaN            |\n",
      "+--------------+-------+------------+-------------------+------------------------+----------+---------------+------+-----------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_codes_iso_df_spark.printSchema()\n",
    "country_codes_iso_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Read I94 Airport code data to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning I94 Airport data first\n",
    "ac = {\"i94port_clean\": [], \"i94_airport_name_clean\": [], \"i94_state_clean\": []}\n",
    "codes = []\n",
    "names = []\n",
    "states = []\n",
    "for index, row in airport_codes_i94_df.iterrows():\n",
    "    y = re.sub(\"'\", \"\", index)\n",
    "    x = re.sub(\"'\", \"\", row[0])\n",
    "    z = re.sub(\"'\", \"\", row[0]).split(\",\")\n",
    "    y = y.strip()\n",
    "    z[0] = z[0].strip()\n",
    "    \n",
    "    if len(z) == 2:\n",
    "        codes.append(y)\n",
    "        names.append(z[0])\n",
    "        z[1] = z[1].strip()\n",
    "        states.append(z[1])\n",
    "    else:\n",
    "        codes.append(y)\n",
    "        names.append(z[0])\n",
    "        states.append(\"NaN\")\n",
    "\n",
    "ac[\"i94port_clean\"] = codes\n",
    "ac[\"i94_airport_name_clean\"] = names\n",
    "ac[\"i94_state_clean\"] = states\n",
    "\n",
    "airport_codes_i94_df_clean = pd.DataFrame.from_dict(ac)\n",
    "\n",
    "ac_path = output_data + \"/airport_codes_i94_clean.csv\"\n",
    "airport_codes_i94_df_clean.to_csv(ac_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_codes_i94_schema = t.StructType([\n",
    "                            t.StructField(\"i94_port\", t.StringType(), False),\n",
    "                            t.StructField(\"i94_airport_name\", t.StringType(), False),\n",
    "                            t.StructField(\"i94_airport_state\", t.StringType(), False)\n",
    "                        ])\n",
    "airport_codes_i94_df_spark = spark.createDataFrame(airport_codes_i94_df_clean, schema=airport_codes_i94_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94_port: string (nullable = false)\n",
      " |-- i94_airport_name: string (nullable = false)\n",
      " |-- i94_airport_state: string (nullable = false)\n",
      "\n",
      "+--------+------------------------+-----------------+\n",
      "|i94_port|i94_airport_name        |i94_airport_state|\n",
      "+--------+------------------------+-----------------+\n",
      "|ALC     |ALCAN                   |AK               |\n",
      "|ANC     |ANCHORAGE               |AK               |\n",
      "|BAR     |BAKER AAF - BAKER ISLAND|AK               |\n",
      "|DAC     |DALTONS CACHE           |AK               |\n",
      "|PIZ     |DEW STATION PT LAY DEW  |AK               |\n",
      "+--------+------------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_i94_df_spark.printSchema()\n",
    "airport_codes_i94_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Read I94 Country Code data to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_codes_i94_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning I94 Country Code data first\n",
    "cc = {\"i94cit_clean\": [],\n",
    "      \"i94_country_name_clean\": [],\n",
    "      \"iso_country_code_clean\" : []\n",
    "      }\n",
    "ccodes = []\n",
    "cnames = []\n",
    "ccodes_iso = []\n",
    "\n",
    "for index, row in country_codes_i94_df.iterrows():\n",
    "    cname = re.sub(\"'\", \"\", row[0]).strip()\n",
    "    ccode_iso = row[1]\n",
    "    ccodes.append(index)\n",
    "    cnames.append(cname)\n",
    "    ccodes_iso.append(ccode_iso)\n",
    "\n",
    "cc[\"i94cit_clean\"] = ccodes\n",
    "cc[\"i94_country_name_clean\"] = cnames\n",
    "cc[\"iso_country_code_clean\"] = ccodes_iso\n",
    "country_codes_i94_df_clean = pd.DataFrame.from_dict(cc)\n",
    "\n",
    "cc_path = input_data + \"/country_codes_i94_clean.csv\"\n",
    "country_codes_i94_df_clean.to_csv(cc_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes_i94_schema = t.StructType([\n",
    "                            t.StructField(\"i94_cit\", t.StringType(), False),\n",
    "                            t.StructField(\"i94_country_name\", t.StringType(), False),\n",
    "                            t.StructField(\"iso_country_code\", t.StringType(), False)\n",
    "                        ])\n",
    "country_codes_i94_df_spark = spark.createDataFrame(country_codes_i94_df_clean, schema=country_codes_i94_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94_cit: string (nullable = false)\n",
      " |-- i94_country_name: string (nullable = false)\n",
      " |-- iso_country_code: string (nullable = false)\n",
      "\n",
      "+-------+----------------+----------------+\n",
      "|i94_cit|i94_country_name|iso_country_code|\n",
      "+-------+----------------+----------------+\n",
      "|582    |MEXICO          |484             |\n",
      "|236    |AFGHANISTAN     |4               |\n",
      "|101    |ALBANIA         |8               |\n",
      "|316    |ALGERIA         |12              |\n",
      "|102    |ANDORRA         |20              |\n",
      "+-------+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_codes_i94_df_spark.printSchema()\n",
    "country_codes_i94_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Write Spark DataFrames to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-15-06-26-27-251294\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S-%f')\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/i94_staging.parquet_2019-08-15-06-26-27-251294\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write I94 Immigration data to parquet file:\n",
    "i94_df_path = output_data + \"i94_staging.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {i94_df_path}\")\n",
    "i94_df_spark.write.mode(\"overwrite\").parquet(i94_df_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "i94_df_spark = spark.read.parquet(i94_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark.printSchema()\n",
    "#i94_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/airport_codes_i94_staging.parquet_2019-08-15-06-26-27-251294\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write I94 Airport data to parquet file:\n",
    "airport_codes_i94_df_path = output_data + \"airport_codes_i94_staging.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {airport_codes_i94_df_path}\")\n",
    "airport_codes_i94_df_spark.write.mode(\"overwrite\").parquet(airport_codes_i94_df_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "airport_codes_i94_df_spark = spark.read.parquet(airport_codes_i94_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airport_codes_i94_df_spark.printSchema()\n",
    "#airport_codes_i94_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/country_codes_i94_staging.parquet_2019-08-20-18-31-37-805734\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write i94 Country data to parquet file:\n",
    "country_codes_i94_df_path = output_data + \"country_codes_i94_staging.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {country_codes_i94_df_path}\")\n",
    "country_codes_i94_df_spark.write.mode(\"overwrite\").parquet(country_codes_i94_df_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "country_codes_i94_df_spark = spark.read.parquet(country_codes_i94_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_codes_i94_df_spark.printSchema()\n",
    "#country_codes_i94_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/airport_codes_iata_staging.parquet_2019-08-15-06-26-27-251294\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write IATA Airport data to parquet file:\n",
    "airport_codes_iata_df_path = output_data + \"airport_codes_iata_staging.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {airport_codes_iata_df_path}\")\n",
    "airport_codes_iata_df_spark.write.mode(\"overwrite\").parquet(airport_codes_iata_df_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "airport_codes_iata_df_spark = spark.read.parquet(airport_codes_iata_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airport_codes_iata_df_spark.printSchema()\n",
    "#airport_codes_iata_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/country_codes_iso_staging.parquet_2019-08-20-18-31-37-805734\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write ISO-3166 Country Code data to parquet file:\n",
    "country_codes_iso_df_path = output_data + \"country_codes_iso_staging.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {country_codes_iso_df_path}\")\n",
    "country_codes_iso_df_spark.write.mode(\"overwrite\").parquet(country_codes_iso_df_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "country_code_iso_df_spark = spark.read.parquet(country_codes_iso_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_codes_iso_df_spark.printSchema()\n",
    "#country_codes_iso_df_spark.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "_Identify data quality issues, like missing values, duplicate data, etc._\n",
    "\n",
    "Input data has the following quality issues:\n",
    "    \n",
    "* I94 Immigration data: \n",
    "    * Most of the columns are missing some info (nulls).\n",
    "    * All missing info need to be filled-in to avoid errors further in the pipeline. \n",
    "    \n",
    "* I94 Airport data: \n",
    "    * Data has quote marks and extra white spaces aftwer copy-paste operation.\n",
    "    * Original data was cleaned-up already before importing to Spark.\n",
    "    \n",
    "* I94 Country code data: \n",
    "    * Data has quote marks and extra white spaces aftwer copy-paste operation.\n",
    "    * Original data was cleaned-up already before importing to Spark.\n",
    "\n",
    "* ISO3166 Country data:\n",
    "    * Antarctica (row) is missing data from some columns.\n",
    "\n",
    "#### Cleaning Steps\n",
    "_Document steps necessary to clean the data_\n",
    "\n",
    "Input data needs the following cleaning operations:\n",
    "* I94 data:\n",
    "    * All missing (null) data is handled in all columns. \n",
    "    * Nulls are replaced with either NA (string), or 0.0 (double).\n",
    "    \n",
    "* I94 Airport data: \n",
    "    * Remove quote marks and extra white spaces from the data.\n",
    "* I94 Country Code data: \n",
    "    * Remove quote marks and extra white spaces from the data.\n",
    "* ISO Country Code data:\n",
    "    * No action required. Antarctica is handled as a special case to avoid duplicate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Clean I94 Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling NULLs DONE.\n"
     ]
    }
   ],
   "source": [
    "i94_df_spark_clean = i94_df_spark.na.fill({'i94mode': 0.0, 'i94addr': 'NA','depdate': 0.0, 'i94bir': 'NA', \\\n",
    "                        'i94visa': 0.0, 'count': 0.0, 'dtadfile': 'NA', 'visapost': 'NA', \\\n",
    "                        'occup': 'NA', 'entdepa': 'NA', 'entdepd': 'NA', 'entdepu': 'NA', \\\n",
    "                        'matflag': 'NA', 'biryear': 0.0, 'dtaddto': 'NA', 'gender': 'NA', \\\n",
    "                        'insnum': 'NA', 'airline': 'NA', 'admnum': 0.0, 'fltno': 'NA', 'visatype': 'NA'})\n",
    "print(\"Filling NULLs DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No cleaning actions. All necessary columns have clean data.\n",
    "i94_df_spark_clean.createOrReplaceTempView(\"immigrants_table_DF\")\n",
    "immigrants_table_check = spark.sql(\"\"\"\n",
    "    SELECT  cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, \\\n",
    "            i94mode, airline, fltno, depdate, i94bir, i94visa, gender,  \\\n",
    "            visatype, admnum\n",
    "    FROM immigrants_table_DF\n",
    "    WHERE   cicid == null OR arrdate == null OR i94port == null \\\n",
    "            OR fltno == null OR i94mode == null OR admnum == null \\\n",
    "            OR gender == null OR admnum == null \n",
    "    ORDER BY arrdate\n",
    "\"\"\")\n",
    "#immigrants_table_check.printSchema()\n",
    "#immigrants_table_check.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+---------+----------+-------------------+\n",
      "|cicid|i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum      |fltno|visatype|person_id|i94res_str|arrival_ts         |\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+---------+----------+-------------------+\n",
      "|7.0  |2016.0|1.0   |101.0 |101.0 |BOS    |20465.0|1.0    |MA     |0.0    |20.0  |3.0    |1.0  |NA      |NA      |NA   |T      |NA     |NA     |NA     |1996.0 |D/S     |M     |NA    |LH     |3.46608285E8|424  |F1      |0        |101       |2016-01-12 00:00:00|\n",
      "|8.0  |2016.0|1.0   |101.0 |101.0 |BOS    |20465.0|1.0    |MA     |0.0    |20.0  |3.0    |1.0  |NA      |NA      |NA   |T      |NA     |NA     |NA     |1996.0 |D/S     |M     |NA    |LH     |3.46627585E8|424  |F1      |1        |101       |2016-01-12 00:00:00|\n",
      "|9.0  |2016.0|1.0   |101.0 |101.0 |BOS    |20469.0|1.0    |CT     |20480.0|17.0  |2.0    |1.0  |NA      |NA      |NA   |T      |N      |NA     |M      |1999.0 |07152016|F     |NA    |AF     |3.81092385E8|338  |B2      |2        |101       |2016-01-16 00:00:00|\n",
      "|10.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20469.0|1.0    |CT     |20499.0|45.0  |2.0    |1.0  |NA      |NA      |NA   |T      |N      |NA     |M      |1971.0 |07152016|F     |NA    |AF     |3.81087885E8|338  |B2      |3        |101       |2016-01-16 00:00:00|\n",
      "|11.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20469.0|1.0    |CT     |20499.0|12.0  |2.0    |1.0  |NA      |NA      |NA   |T      |N      |NA     |M      |2004.0 |07152016|M     |NA    |AF     |3.81078685E8|338  |B2      |4        |101       |2016-01-16 00:00:00|\n",
      "|12.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20474.0|1.0    |MA     |0.0    |33.0  |2.0    |1.0  |NA      |NA      |NA   |T      |NA     |NA     |NA     |1983.0 |07202016|M     |NA    |LH     |4.06155985E8|424  |B2      |5        |101       |2016-01-21 00:00:00|\n",
      "|15.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20477.0|1.0    |MA     |20524.0|28.0  |3.0    |1.0  |NA      |NA      |NA   |T      |O      |NA     |M      |1988.0 |D/S     |F     |NA    |LH     |4.17363085E8|424  |F1      |6        |101       |2016-01-24 00:00:00|\n",
      "|17.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20480.0|1.0    |MA     |0.0    |78.0  |2.0    |1.0  |NA      |NA      |NA   |T      |NA     |NA     |NA     |1938.0 |07262016|M     |NA    |TK     |4.28558285E8|81   |B2      |7        |101       |2016-01-27 00:00:00|\n",
      "|18.0 |2016.0|1.0   |101.0 |101.0 |BOS    |20480.0|1.0    |MA     |0.0    |70.0  |2.0    |1.0  |NA      |NA      |NA   |T      |NA     |NA     |NA     |1946.0 |07262016|F     |NA    |TK     |4.28561085E8|81   |B2      |8        |101       |2016-01-27 00:00:00|\n",
      "|20.0 |2016.0|1.0   |101.0 |101.0 |CHI    |20473.0|1.0    |IL     |20482.0|28.0  |2.0    |1.0  |NA      |NA      |NA   |T      |O      |NA     |M      |1988.0 |07192016|M     |NA    |BA     |4.01779785E8|295  |B2      |9        |101       |2016-01-20 00:00:00|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+---------+----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#i94_df_spark_clean.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Clean I94 Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port_clean</th>\n",
       "      <th>i94_airport_name_clean</th>\n",
       "      <th>i94_state_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTH</td>\n",
       "      <td>DUTCH HARBOR</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EGL</td>\n",
       "      <td>EAGLE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRB</td>\n",
       "      <td>FAIRBANKS</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOM</td>\n",
       "      <td>HOMER</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HYD</td>\n",
       "      <td>HYDER</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94port_clean    i94_airport_name_clean i94_state_clean\n",
       "0           ALC                     ALCAN              AK\n",
       "1           ANC                 ANCHORAGE              AK\n",
       "2           BAR  BAKER AAF - BAKER ISLAND              AK\n",
       "3           DAC             DALTONS CACHE              AK\n",
       "4           PIZ    DEW STATION PT LAY DEW              AK\n",
       "5           DTH              DUTCH HARBOR              AK\n",
       "6           EGL                     EAGLE              AK\n",
       "7           FRB                 FAIRBANKS              AK\n",
       "8           HOM                     HOMER              AK\n",
       "9           HYD                     HYDER              AK"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes_i94_df_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Clean I94 Country Code data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94cit_clean</th>\n",
       "      <th>i94_country_name_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94cit_clean i94_country_name_clean\n",
       "0           582                 MEXICO\n",
       "1           236            AFGHANISTAN\n",
       "2           101                ALBANIA\n",
       "3           316                ALGERIA\n",
       "4           102                ANDORRA\n",
       "5           324                 ANGOLA\n",
       "6           529               ANGUILLA\n",
       "7           518        ANTIGUA-BARBUDA\n",
       "8           687              ARGENTINA\n",
       "9           151                ARMENIA"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_i94_df_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Clean ISO Country Codes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alpha-2: string (nullable = false)\n",
      " |-- alpha-3: string (nullable = false)\n",
      " |-- country-code: string (nullable = false)\n",
      " |-- intermediate-region: string (nullable = false)\n",
      " |-- intermediate-region-code: string (nullable = false)\n",
      " |-- iso-3166-2: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- region: string (nullable = true)\n",
      " |-- region-code: string (nullable = true)\n",
      " |-- sub-region: string (nullable = true)\n",
      " |-- sub-region-code: string (nullable = true)\n",
      "\n",
      "+--------------+-------+------------+-------------------+------------------------+----------+---------------+------+-----------+----------+---------------+\n",
      "|alpha-2       |alpha-3|country-code|intermediate-region|intermediate-region-code|iso-3166-2|name           |region|region-code|sub-region|sub-region-code|\n",
      "+--------------+-------+------------+-------------------+------------------------+----------+---------------+------+-----------+----------+---------------+\n",
      "|Afghanistan   |AF     |AFG         |4                  |ISO 3166-2:AF           |Asia      |Southern Asia  |NaN   |142.0      |34.0      |NaN            |\n",
      "|Åland Islands |AX     |ALA         |248                |ISO 3166-2:AX           |Europe    |Northern Europe|NaN   |150.0      |154.0     |NaN            |\n",
      "|Albania       |AL     |ALB         |8                  |ISO 3166-2:AL           |Europe    |Southern Europe|NaN   |150.0      |39.0      |NaN            |\n",
      "|Algeria       |DZ     |DZA         |12                 |ISO 3166-2:DZ           |Africa    |Northern Africa|NaN   |2.0        |15.0      |NaN            |\n",
      "|American Samoa|AS     |ASM         |16                 |ISO 3166-2:AS           |Oceania   |Polynesia      |NaN   |9.0        |61.0      |NaN            |\n",
      "+--------------+-------+------------+-------------------+------------------------+----------+---------------+------+-----------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_iso_df_spark.printSchema()\n",
    "country_codes_iso_df_spark.show(5, truncate=False)\n",
    "country_codes_iso_df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling NULLs DONE.\n"
     ]
    }
   ],
   "source": [
    "country_codes_iso_df_spark_clean = country_codes_iso_df_spark\\\n",
    "                                        .na.fill({  'alpha_2': 'NA', \\\n",
    "                                                    'alpha_3': 'NA', \\\n",
    "                                                    'country_code': 0, \\\n",
    "                                                    'intermediate_region': 'NA', \\\n",
    "                                                    'intermediate_region_code': 'NA', \\\n",
    "                                                    'iso_3166_2': 'NA', \\\n",
    "                                                    'name': 'NA', \\\n",
    "                                                    'region': 'NA', \\\n",
    "                                                    'region_code': 'NA', \\\n",
    "                                                    'sub_region': 'NA', \\\n",
    "                                                    'sub_region_code': 'NA'})\n",
    "print(\"Filling NULLs DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_codes_iso_df_spark_clean.filter(country_codes_iso_df_spark_clean.name == \"Antarctica\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_codes_iso_df_spark_clean.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "_Map out the conceptual data model and explain why you chose that model_\n",
    "\n",
    "I94 Immigration Insights data models is a star models consisting of 4 Dimensions table and 1 Fact table:\n",
    "  * Dimensions tables:\n",
    "      * admissions table\n",
    "      * countries table\n",
    "      * airports table\n",
    "      * time table\n",
    "  * Fact table:\n",
    "      * immigrations table\n",
    "      \n",
    "ERD for the project:\n",
    "![I94-ImmigrationInsights data schema as ER Diagram](./Udacity-DEND-Project-Capstone-ERD-20190820v11.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "_List the steps necessary to pipeline the data into the chosen data model_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-20-18-31-37-805734\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "start_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S-%f')\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Create admissions table + write to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- admission_nbr: double (nullable = false)\n",
      " |-- country_code: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- visa_code: double (nullable = false)\n",
      " |-- visa_type: string (nullable = false)\n",
      " |-- person_gender: string (nullable = false)\n",
      "\n",
      "+--------------+------------+----+---------+---------+-------------+\n",
      "| admission_nbr|country_code| age|visa_code|visa_type|person_gender|\n",
      "+--------------+------------+----+---------+---------+-------------+\n",
      "|8.453557203E10|       101.0|42.0|      1.0|       E2|            M|\n",
      "|8.561559603E10|       101.0|21.0|      3.0|       F1|            M|\n",
      "|8.699082343E10|       101.0|55.0|      2.0|       B2|            M|\n",
      "|8.625841873E10|       101.0|43.0|      1.0|       E2|            M|\n",
      "|8.417612603E10|       101.0|19.0|      3.0|       F1|            F|\n",
      "|  4.20447685E8|       101.0|62.0|      2.0|       B2|            F|\n",
      "|8.574210703E10|       101.0|25.0|      3.0|       F1|            M|\n",
      "|8.634534993E10|       101.0|24.0|      3.0|       F1|            M|\n",
      "|8.634298943E10|       101.0|60.0|      2.0|       B2|            F|\n",
      "|  3.37702985E8|       101.0|21.0|      3.0|       F1|            M|\n",
      "|8.473907113E10|       101.0|41.0|      2.0|       B2|            M|\n",
      "|8.542788393E10|       101.0|20.0|      3.0|       F1|            F|\n",
      "|8.455643453E10|       101.0|23.0|      3.0|       F1|            F|\n",
      "|8.678389143E10|       101.0|60.0|      2.0|       B2|           NA|\n",
      "|8.698559203E10|       101.0|63.0|      2.0|       B2|            F|\n",
      "|8.120841773E10|       101.0|26.0|      2.0|       B2|            M|\n",
      "|8.410376163E10|       101.0|11.0|      1.0|       E2|            M|\n",
      "|  3.75553985E8|       101.0|69.0|      2.0|       B2|            M|\n",
      "|8.485861733E10|       101.0|24.0|      3.0|       F1|            M|\n",
      "|8.506346023E10|       101.0|61.0|      2.0|       B2|            F|\n",
      "+--------------+------------+----+---------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "#i94_df_spark = i94_df_spark.withColumn(\"person_id\", monotonically_increasing_id())\n",
    "i94_df_spark_clean.createOrReplaceTempView(\"admissions_table_DF\")\n",
    "admissions_table = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT admnum   AS admission_nbr,\n",
    "                     i94res   AS country_code, \n",
    "                     i94bir   AS age, \n",
    "                     i94visa  AS visa_code, \n",
    "                     visatype AS visa_type, \n",
    "                     gender   AS person_gender\n",
    "    FROM admissions_table_DF\n",
    "    ORDER BY country_code\n",
    "\"\"\")\n",
    "admissions_table.printSchema()\n",
    "#admissions_table.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/admissions_table.parquet_2019-08-20-18-31-37-805734\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write admissions_table to parquet file:\n",
    "admissions_table_path = output_data + \"admissions_table.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {admissions_table_path}\")\n",
    "admissions_table.write.mode(\"overwrite\").parquet(admissions_table_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "admissions_table_df = spark.read.parquet(admissions_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Create countries table + write to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94_cit: string (nullable = false)\n",
      " |-- i94_country_name: string (nullable = false)\n",
      " |-- iso_country_code: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_i94_df_spark.printSchema()\n",
    "#country_codes_i94_df_spark.head()\n",
    "country_codes_i94_df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alpha_2: string (nullable = false)\n",
      " |-- alpha_3: string (nullable = false)\n",
      " |-- country_code: string (nullable = false)\n",
      " |-- intermediate_region: string (nullable = false)\n",
      " |-- intermediate_region_code: string (nullable = false)\n",
      " |-- iso_3166_2: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- region: string (nullable = true)\n",
      " |-- region_code: string (nullable = true)\n",
      " |-- sub_region: string (nullable = true)\n",
      " |-- sub_region_code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes_iso_df_spark.printSchema()\n",
    "country_codes_iso_df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark_joined = i94_df_spark.join(country_codes_i94_df_spark, \\\n",
    "#                                        (i94_df_spark.i94res_str == country_codes_i94_df_spark.i94cit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark_joined.printSchema()\n",
    "#i94_df_spark_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847924"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i94_df_spark_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tables\n",
    "country_codes_i94_df_spark_joined = country_codes_i94_df_spark\\\n",
    "                                        .join(country_codes_iso_df_spark, \\\n",
    "                                            (country_codes_i94_df_spark.iso_country_code == \\\n",
    "                                                    country_codes_iso_df_spark.country_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = false)\n",
      " |-- country_name: string (nullable = false)\n",
      " |-- iso_ccode: string (nullable = false)\n",
      " |-- iso_alpha_2: string (nullable = false)\n",
      " |-- iso_alpha_3: string (nullable = false)\n",
      " |-- iso_3166_2_code: string (nullable = false)\n",
      " |-- iso_country_name: string (nullable = false)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- iso_sub_region: string (nullable = true)\n",
      " |-- iso_region_code: string (nullable = true)\n",
      " |-- iso_sub_region_code: string (nullable = true)\n",
      "\n",
      "+------------+------------+---------+-----------+-----------+---------------+----------------+----------+--------------+---------------+-------------------+\n",
      "|country_code|country_name|iso_ccode|iso_alpha_2|iso_alpha_3|iso_3166_2_code|iso_country_name|iso_region|iso_sub_region|iso_region_code|iso_sub_region_code|\n",
      "+------------+------------+---------+-----------+-----------+---------------+----------------+----------+--------------+---------------+-------------------+\n",
      "+------------+------------+---------+-----------+-----------+---------------+----------------+----------+--------------+---------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table\n",
    "country_codes_i94_df_spark_joined.createOrReplaceTempView(\"countries_table_DF\")\n",
    "countries_table = spark.sql(\"\"\"\n",
    "        SELECT DISTINCT i94_cit          AS country_code,\n",
    "                        i94_country_name AS country_name,\n",
    "                        iso_country_code AS iso_ccode,\n",
    "                        alpha_2          AS iso_alpha_2,\n",
    "                        alpha_3          AS iso_alpha_3,\n",
    "                        iso_3166_2       AS iso_3166_2_code,\n",
    "                        name             AS iso_country_name,\n",
    "                        region           AS iso_region,\n",
    "                        sub_region       AS iso_sub_region,\n",
    "                        region_code      AS iso_region_code,\n",
    "                        sub_region_code  AS iso_sub_region_code\n",
    "        FROM countries_table_DF          AS countries\n",
    "        ORDER BY country_name\n",
    "    \n",
    "\"\"\")\n",
    "countries_table.printSchema()\n",
    "countries_table.show(20)\n",
    "countries_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/countries_table.parquet_2019-08-20-15-01-43-299686\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write countries_table to parquet file:\n",
    "countries_table_path = output_data + \"countries_table.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {countries_table_path}\")\n",
    "countries_table.write.mode(\"overwrite\").parquet(countries_table_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "countries_table_df = spark.read.parquet(countries_table_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Create airports table + write to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94_airport_name: string (nullable = true)\n",
      " |-- i94_airport_state: string (nullable = true)\n",
      "\n",
      "+-------+--------------------------+-----------------+\n",
      "|i94port|i94_airport_name          |i94_airport_state|\n",
      "+-------+--------------------------+-----------------+\n",
      "|ELM    |REGIONAL ARPT - HORSEHEAD |NY               |\n",
      "|ROC    |ROCHESTER                 |NY               |\n",
      "|ROU    |ROUSES POINT              |NY               |\n",
      "|SWF    |STEWART - ORANGE CNTY     |NY               |\n",
      "|SYR    |SYRACUSE                  |NY               |\n",
      "|THO    |THOUSAND ISLAND BRIDGE    |NY               |\n",
      "|TRO    |TROUT RIVER               |NY               |\n",
      "|WAT    |WATERTOWN                 |NY               |\n",
      "|HPN    |WESTCHESTER - WHITE PLAINS|NY               |\n",
      "|WRB    |WHIRLPOOL BRIDGE          |NY               |\n",
      "|YOU    |YOUNGSTOWN                |NY               |\n",
      "|AKR    |AKRON                     |OH               |\n",
      "|ATB    |ASHTABULA                 |OH               |\n",
      "|CIN    |CINCINNATI                |OH               |\n",
      "|CLE    |CLEVELAND                 |OH               |\n",
      "+-------+--------------------------+-----------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#airport_codes_i94_df_spark.printSchema()\n",
    "#airport_codes_i94_df_spark.show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_id: string (nullable = false)\n",
      " |-- airport_name: string (nullable = false)\n",
      " |-- airport_state: string (nullable = false)\n",
      "\n",
      "+----------+--------------------+-------------+\n",
      "|airport_id|        airport_name|airport_state|\n",
      "+----------+--------------------+-------------+\n",
      "|       ABE|            ABERDEEN|           WA|\n",
      "|       ADS|ADDISON AIRPORT- ...|           TX|\n",
      "|       AGA|               AGANA|           GU|\n",
      "|       AGU|           AGUADILLA|           PR|\n",
      "|       BOI|AIR TERM. (GOWEN ...|           ID|\n",
      "|       CAK|               AKRON|           OH|\n",
      "|       AKR|               AKRON|           OH|\n",
      "|       ALA|          ALAMAGORDO|     NM (BPS)|\n",
      "|       ALB|              ALBANY|           NY|\n",
      "|       CHO|ALBEMARLE CHARLOT...|           VA|\n",
      "|       ABQ|         ALBUQUERQUE|           NM|\n",
      "|       ABG|              ALBURG|           VT|\n",
      "|       ABS|      ALBURG SPRINGS|           VT|\n",
      "|       ALC|               ALCAN|           AK|\n",
      "|       AXB|      ALEXANDRIA BAY|           NY|\n",
      "|       AGM|              ALGOMA|           WI|\n",
      "|       AGN|             ALGONAC|           MI|\n",
      "|       ALP|              ALPENA|           MI|\n",
      "|       AMB|             AMBROSE|           ND|\n",
      "|       ADT|         AMISTAD DAM|           TX|\n",
      "+----------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table\n",
    "airport_codes_i94_df_spark.createOrReplaceTempView(\"airports_table_DF\")\n",
    "airports_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT  i94_port          AS airport_id, \n",
    "                     i94_airport_name  AS airport_name,\n",
    "                     i94_airport_state AS airport_state\n",
    "    FROM airports_table_DF             AS airports\n",
    "    ORDER BY airport_name\n",
    "\"\"\")\n",
    "\n",
    "airports_table.printSchema()\n",
    "airports_table.show(20)\n",
    "airports_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/airports_table.parquet_2019-08-20-15-01-43-299686\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write airports_table to parquet file:\n",
    "airports_table_path = output_data + \"airports_table.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {airports_table_path}\")\n",
    "airports_table.write.mode(\"overwrite\").parquet(airports_table_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "airports_table_df = spark.read.parquet(airports_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Create time table + write to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column creation DONE.\n"
     ]
    }
   ],
   "source": [
    "@udf(t.TimestampType())\n",
    "def get_timestamp (arrdate):\n",
    "    arrdate_int = int(arrdate)\n",
    "    return (datetime(1960,1,1) + timedelta(days=arrdate_int))\n",
    "    \n",
    "i94_df_spark_clean = i94_df_spark_clean.withColumn(\"arrival_time\", get_timestamp(i94_df_spark.arrdate))\n",
    "print(\"New column creation DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- arrival_ts: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_spark_clean.createOrReplaceTempView(\"time_table_DF\")\n",
    "time_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT  arrival_time           AS arrival_ts, \n",
    "                     hour(arrival_time)       AS hour, \n",
    "                     day(arrival_time)        AS day, \n",
    "                     weekofyear(arrival_time) AS week,\n",
    "                     month(arrival_time)      AS month,\n",
    "                     year(arrival_time)       AS year,\n",
    "                     dayofweek(arrival_time)  AS weekday\n",
    "    FROM time_table_DF\n",
    "\"\"\")\n",
    "time_table.printSchema()\n",
    "#time_table.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/time_table.parquet_2019-08-20-15-01-43-299686\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-cc63cef62773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"OUTPUT: {time_table_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtime_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"month\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                   \u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_table_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Writing DONE.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacity-dend-py37/lib/python3.6/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacity-dend-py37/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/envs/udacity-dend-py37/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacity-dend-py37/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacity-dend-py37/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Write time_table to parquet file:\n",
    "time_table_path = output_data + \"time_table.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {time_table_path}\")\n",
    "time_table.write.mode(\"overwrite\").partitionBy(\"year\", \"month\")\\\n",
    "                                  .parquet(time_table_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "time_table_df = spark.read.parquet(time_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5 Create immigrations table + write to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries_table_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"depdate_ts\" column at this phase (before joining tables)\n",
    "# Create \"immigration_id\" column at this phase (before joining tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_df_spark_joined = i94_df_spark_clean.join(country_codes_i94_df_spark, \\\n",
    "                                              (i94_df_spark_clean.i94cit == country_codes_i94_df_spark.i94_cit))\\\n",
    "                                        .join(airport_codes_i94_df_spark, \\\n",
    "                                              (i94_df_spark_clean.i94port == airport_codes_i94_df_spark.i94_port))\\\n",
    "                                        .join(time_table_df, \\\n",
    "                                                            i94_df_spark_clean.arrival_time == \\\n",
    "                                                            time_table_df.arrival_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = false)\n",
      " |-- i94addr: string (nullable = false)\n",
      " |-- depdate: double (nullable = false)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = false)\n",
      " |-- count: double (nullable = false)\n",
      " |-- dtadfile: string (nullable = false)\n",
      " |-- visapost: string (nullable = false)\n",
      " |-- occup: string (nullable = false)\n",
      " |-- entdepa: string (nullable = false)\n",
      " |-- entdepd: string (nullable = false)\n",
      " |-- entdepu: string (nullable = false)\n",
      " |-- matflag: string (nullable = false)\n",
      " |-- biryear: double (nullable = false)\n",
      " |-- dtaddto: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- insnum: string (nullable = false)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- admnum: double (nullable = false)\n",
      " |-- fltno: string (nullable = false)\n",
      " |-- visatype: string (nullable = false)\n",
      " |-- person_id: long (nullable = false)\n",
      " |-- i94res_str: string (nullable = true)\n",
      " |-- arrival_ts: timestamp (nullable = true)\n",
      " |-- i94_cit: string (nullable = false)\n",
      " |-- i94_country_name: string (nullable = false)\n",
      " |-- i94_port: string (nullable = false)\n",
      " |-- i94_airport_name: string (nullable = false)\n",
      " |-- i94_airport_state: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_spark_joined.printSchema()\n",
    "#i94_df_spark_joined.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column creation DONE.\n"
     ]
    }
   ],
   "source": [
    "i94_df_spark_joined = i94_df_spark_joined.withColumn(\"immigration_id\", monotonically_increasing_id())\n",
    "print(\"New column creation DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark_joined.printSchema()\n",
    "#i94_df_spark_joined.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = false)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- fltno: string (nullable = false)\n",
      " |-- depdate: double (nullable = false)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- visatype: string (nullable = false)\n",
      " |-- admnum: double (nullable = false)\n",
      "\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-----+-------+------+-------+------+--------+------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|airline|fltno|depdate|i94bir|i94visa|gender|visatype|admnum|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-----+-------+------+-------+------+--------+------+\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-----+-------+------+-------+------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_spark_joined.createOrReplaceTempView(\"immigrants_table_DF\")\n",
    "immigrants_table_check = spark.sql(\"\"\"\n",
    "    SELECT  cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, \\\n",
    "            i94mode, airline, fltno, depdate, i94bir, i94visa, gender,  \\\n",
    "            visatype, admnum\n",
    "    FROM immigrants_table_DF\n",
    "    WHERE   cicid == null OR arrdate == null OR i94port == null \\\n",
    "            OR fltno == null OR i94mode == null OR admnum == null \\\n",
    "            OR gender == null OR admnum == null OR depdate == null\n",
    "    ORDER BY arrdate\n",
    "\"\"\")\n",
    "immigrants_table_check.printSchema()\n",
    "immigrants_table_check.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column creation DONE.\n"
     ]
    }
   ],
   "source": [
    "@udf(t.TimestampType())\n",
    "def get_timestamp2 (depdate):\n",
    "    if depdate == \"null\":\n",
    "        depdate_int = 0\n",
    "    else:\n",
    "        depdate_int = int(depdate)\n",
    "    return (datetime(1960,1,1) + timedelta(days=depdate_int))\n",
    "\n",
    "i94_df_spark_joined = i94_df_spark_joined.withColumn(\"departure_date\", get_timestamp2(i94_df_spark_joined.depdate))\n",
    "print(\"New column creation DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_df_spark_joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- immigration_id: long (nullable = false)\n",
      " |-- arrival_ts: timestamp (nullable = true)\n",
      " |-- airport_id: string (nullable = false)\n",
      " |-- country_code: string (nullable = false)\n",
      " |-- admission_nbr: double (nullable = false)\n",
      " |-- arrival_mode: double (nullable = false)\n",
      " |-- departure_date: timestamp (nullable = true)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- flight_nbr: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i94_df_spark_joined.createOrReplaceTempView(\"immigrations_table_DF\")\n",
    "immigrations_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT  immigration_id AS immigration_id, \n",
    "                     arrival_time   AS arrival_ts,\n",
    "                     year           AS arrival_year,\n",
    "                     month          AS arrival_month,\n",
    "                     i94_port       AS airport_id,\n",
    "                     i94_cit        AS country_code,\n",
    "                     admnum         AS admission_nbr,\n",
    "                     i94mode        AS arrival_mode,\n",
    "                     departure_date AS departure_date,\n",
    "                     airline        AS airline,\n",
    "                     fltno          AS flight_nbr\n",
    "                    \n",
    "    FROM immigrations_table_DF immigrants\n",
    "    ORDER BY arrival_time\n",
    "\"\"\")\n",
    "immigrations_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------+------------+---------------+------------+-------------------+-------+----------+\n",
      "|immigration_id|arrival_ts         |airport_id|country_code|admission_nbr  |arrival_mode|departure_date     |airline|flight_nbr|\n",
      "+--------------+-------------------+----------+------------+---------------+------------+-------------------+-------+----------+\n",
      "|154618828633  |2016-01-01 00:00:00|DET       |245         |8.412547383E10 |1.0         |1960-01-01 00:00:00|DL     |00158     |\n",
      "|214748373269  |2016-01-01 00:00:00|AGA       |209         |4.0342039033E10|1.0         |2016-01-05 00:00:00|DL     |00294     |\n",
      "|154618838773  |2016-01-01 00:00:00|DET       |245         |8.216838953E10 |3.0         |2016-01-06 00:00:00|NA     |01862     |\n",
      "|34359738956   |2016-01-01 00:00:00|SNA       |582         |8.418162053E10 |1.0         |2016-01-08 00:00:00|4O     |02952     |\n",
      "|154618838939  |2016-01-01 00:00:00|DET       |245         |7.365205013E10 |3.0         |2016-03-13 00:00:00|NA     |00806     |\n",
      "+--------------+-------------------+----------+------------+---------------+------------+-------------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigrations_table.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: data/output_data/immigrations_table.parquet_2019-08-15-12-22-26-417652\n",
      "Writing DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write immigrants_table to parquet file:\n",
    "immigrations_table_path = output_data + \"immigrations_table.parquet\" + \"_\" + start_time\n",
    "print(f\"OUTPUT: {immigrations_table_path}\")\n",
    "immigrations_table.write.mode(\"overwrite\").partitionBy(\"arrival_year\", \"arrival_month\")\\\n",
    "                                          .parquet(immigrations_table_path)\n",
    "print(\"Writing DONE.\")\n",
    "\n",
    "# Read parquet file back to Spark:\n",
    "immigrations_table_df = spark.read.parquet(immigrations_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "_Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:_\n",
    " * _Integrity constraints on the relational database (e.g., unique key, data type, etc.)_\n",
    " * _Unit tests for the scripts to ensure they are doing the right thing_\n",
    " * _Source/Count checks to ensure completeness_\n",
    " \n",
    "_Run Quality Checks_\n",
    "\n",
    "Data quality checks:\n",
    " * Check that all primary and secondary keys in star schema dimension and fact tables have values.\n",
    " * Check that all tables have more than 0 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_ts = start_time\n",
    "results = { \"round_ts\": round_ts,\n",
    "            \"admissions\": \"\",\n",
    "            \"countries\": \"\",\n",
    "            \"airports\": \"\",\n",
    "            \"time\": \"\",\n",
    "            \"immigrations\": \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Quality checks for admissions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that key fields have valid values (no nulls or empty)\n",
    "admissions_table_df.createOrReplaceTempView(\"admissions_table_DF\")\n",
    "admissions_table_check1 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM admissions_table_DF\n",
    "    WHERE   admission_nbr IS NULL OR admission_nbr == \"\" OR \n",
    "            country_code IS NULL OR country_code == \"\" \n",
    "\"\"\")\n",
    "admissions_table_check1.show(1)\n",
    "admissions_table_check1.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2833480|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2833480"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that table has > 0 rows\n",
    "admissions_table_df.createOrReplaceTempView(\"admissions_table_DF\")\n",
    "admissions_table_check2 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM admissions_table_DF\n",
    "\"\"\")\n",
    "admissions_table_check2.show(1)\n",
    "admissions_table_check2.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS: {'round_ts': '2019-08-20-15-01-43-299686', 'admissions': 'OK', 'countries': '', 'airports': '', 'time': '', 'immigrations': ''}\n"
     ]
    }
   ],
   "source": [
    "if admissions_table_check1.collect()[0][0] > 0 & admissions_table_check2.collect()[0][0] < 1:\n",
    "    results['admissions'] = \"NOK\"\n",
    "else:\n",
    "    results['admissions'] = \"OK\"\n",
    "\n",
    "print(f\"RESULTS: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Quality checks for countries table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countries_table_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-90f01ea042a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check that key fields have valid values (no nulls or empty)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcountries_table_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"countries_table_DF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m countries_table_check1 = spark.sql(\"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mSELECT\u001b[0m  \u001b[0mCOUNT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFROM\u001b[0m \u001b[0mcountries_table_DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countries_table_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check that key fields have valid values (no nulls or empty)\n",
    "countries_table_df.createOrReplaceTempView(\"countries_table_DF\")\n",
    "countries_table_check1 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM countries_table_DF\n",
    "    WHERE   country_code IS NULL OR country_code == \"\"\n",
    "\"\"\")\n",
    "countries_table_check1.show(1)\n",
    "countries_table_check1.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countries_table_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-6ba4f107d8a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check that table has > 0 rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcountries_table_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"countries_table_DF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m countries_table_check2 = spark.sql(\"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mSELECT\u001b[0m  \u001b[0mCOUNT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFROM\u001b[0m \u001b[0mcountries_table_DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countries_table_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check that table has > 0 rows\n",
    "countries_table_df.createOrReplaceTempView(\"countries_table_DF\")\n",
    "countries_table_check2 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM countries_table_DF\n",
    "\"\"\")\n",
    "countries_table_check2.show(1)\n",
    "countries_table_check2.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countries_table_check1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-386d5e5c5cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mcountries_table_check1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcountries_table_check2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countries'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NOK\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'countries'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countries_table_check1' is not defined"
     ]
    }
   ],
   "source": [
    "if countries_table_check1.collect()[0][0] > 0 & countries_table_check2.collect()[0][0] < 1:\n",
    "    results['countries'] = \"NOK\"\n",
    "else:\n",
    "    results['countries'] = \"OK\"\n",
    "\n",
    "print(f\"RESULTS: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Quality checks for airports table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that key fields have valid values (no nulls or empty)\n",
    "airports_table_df.createOrReplaceTempView(\"airports_table_DF\")\n",
    "airports_table_check1 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM airports_table_DF\n",
    "    WHERE   airport_id IS NULL OR airport_id == \"\" OR\n",
    "            airport_name IS NULL OR airport_name == \"\"\n",
    "\"\"\")\n",
    "airports_table_check1.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     660|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that table has > 0 rows\n",
    "airports_table_df.createOrReplaceTempView(\"airports_table_DF\")\n",
    "airports_table_check2 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM airports_table_DF\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Quality checks for time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that key fields have valid values (no nulls or empty)\n",
    "time_table_df.createOrReplaceTempView(\"time_table_DF\")\n",
    "time_table_check1 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM time_table_DF\n",
    "    WHERE   arrival_ts IS NULL OR arrival_ts == \"\"\n",
    "\"\"\")\n",
    "time_table_check1.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      31|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that table has > 0 rows\n",
    "time_table_df.createOrReplaceTempView(\"time_table_DF\")\n",
    "time_table_check2 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM time_table_DF\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Quality checks for immigrations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that key fields have valid values (no nulls or empty)\n",
    "immigrations_table_df.createOrReplaceTempView(\"immigrations_table_DF\")\n",
    "immigrations_table_check1 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM immigrations_table_DF\n",
    "    WHERE   immigration_id IS NULL OR immigration_id == \"\" OR\n",
    "            arrival_ts IS NULL OR arrival_ts == \"\" OR\n",
    "            airport_id IS NULL OR airport_id == \"\" OR\n",
    "            country_code IS NULL OR country_code == \"\" OR \n",
    "            admission_nbr IS NULL OR admission_nbr == \"\"\n",
    "\"\"\")\n",
    "immigrations_table_check1.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2450639|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that table has > 0 rows\n",
    "immigrations_table_df.createOrReplaceTempView(\"immigrations_table_DF\")\n",
    "immigrations_table_check2 = spark.sql(\"\"\"\n",
    "    SELECT  COUNT(*)\n",
    "    FROM immigrations_table_DF\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "_Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file._\n",
    "\n",
    "Data Dictionary for the project is described in **data_dictionary.json** file stored in the project root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
